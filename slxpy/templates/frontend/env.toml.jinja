## Config version. DO NOT CHANGE.
__version__ = "{{config.VERSION}}"

## Generate raw environment wrapper.
use_raw = {{config.use_raw | tf}}

## Generate gym-flavor environment wrapper (tensor action, tensor observation).
## NOTE: gym-flavor environment has to meet certain criteria. See "gym" section below.
use_gym = {{config.use_gym | tf}}

## Environment initialization needs randomness (generally true).
use_rng = {{config.use_rng | tf}}

## Generate vectorized wrapper over raw/gym environment.
use_vec = {{config.use_vec | tf}}

## Vectorized wrapper use parallel execution.
## Benificial when the env is computationally intensive (CPU-bounded).
## For memory-bounded tasks, this is not very effective.
vec_parallel = {{config.vec_parallel | tf}}

## Configure gym-simulink mapping.
[gym]
    ## Action key in model inport(s).
    ## Data MUST be a double scalar or array.
    ## By default, the 1st inport is taken (Generally only one inport is sensible).
    ## Uncomment the line below to provide an alternative key.
    # action_key = "act"

    ## Observation key in model outports.
    ## Data MUST be a double scalar or array.
    ## By default, the 1st outport is taken.
    ## Uncomment the line below to provide an alternative key.
    # observation_key = "obs"

    ## Reward key in model outports.
    ## Data MUST be a double scalar.
    ## By default, the 2nd outport is taken.
    ## Uncomment the line below to provide an alternative key.
    # reward_key = "rew"

    ## Done key in model outports.
    ## Data MUST be a boolean (or logical in MATLAB) scalar.
    ## By default, the 3rd outport is taken.
    ## Uncomment the line below to provide an alternative key.
    # done_key = "done"

    ## Put additional outports to info dict.
    ## Option: true -> all additional outports are included
    ##         false -> empty info dict
    ##         list of keys -> selected outports are included, e.g. ["foo", "bar"]
    info = {{config.gym.info | tf}}

    ## Implicit type coercion for observation and action
    type_coercion = {{config.gym.type_coercion | tf}}

    ## Reward range, e.g. ["-inf", "inf"] | ["-inf", 0] | [-10, 10]
    reward_range = ["-inf", "inf"]

    ## Action space, similar to gym.space
    ## "type" includes: Box, Discrete, MultiDiscrete, MultiBinary
    [gym.action_space]
        type = "Box"
        low = {{config.gym.action_space.low}}
        high = {{config.gym.action_space.high}}
        shape = [{{config.gym.action_space.shape | join(', ')}}]
        dtype = "{{config.gym.action_space.dtype.name}}"

    ## Observation space, see action_space above
    [gym.observation_space]
        type = "Box"
        low = {{config.gym.observation_space.low}}
        high = {{config.gym.observation_space.high}}
        shape = [{{config.gym.observation_space.shape | join(', ')}}]
        dtype = "{{config.gym.observation_space.dtype.name}}"

## Options controlling reset behavior
[reset]
    ## Take one step after environment initialization to get initial observation.
    ## If set to true/false, optionally provide a initializer for initial input/output.
    first_step = {{config.reset.first_step | tf}}

    ## Only valid when "first_step = true".
    ## By default, initial input is initialized with "default initialization".
    ## Uncomment the line below to provide an "aggregate initialization" list.
    # input = "{}"

    ## Only valid when "first_step = false".
    ## By default, initial output is initialized with "default initialization"
    ## and might be affected by const block output optimization.
    ## Uncomment the line below to provide an "aggregate initialization" list.
    # output = "{}"

## A table to define individual parameter initialization policy
[parameter]

# [parameter.foo]
#     type = "seed"

# [parameter.bar]
#     type = "constant"
#     value = 1.0

# [parameter.baz]
#     type = "uniform"
#     low = 0.0
#     high = 1.0
